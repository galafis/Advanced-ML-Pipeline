# Advanced Machine Learning Pipeline

## ğŸ–¼ï¸ Hero Image

![Hero Image](outputs/hero_image.png)


![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat&logo=matplotlib&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=flat&logo=python&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

An advanced Machine Learning Pipeline that automates the entire ML workflow, from data preprocessing to model evaluation. This project demonstrates advanced data science techniques including automated exploratory analysis, feature engineering, model comparison, and hyperparameter optimization.

Pipeline avanÃ§ado de Machine Learning que automatiza todo o fluxo de trabalho ML, desde o prÃ©-processamento de dados atÃ© a avaliaÃ§Ã£o de modelos. Este projeto demonstra tÃ©cnicas avanÃ§adas de ciÃªncia de dados incluindo anÃ¡lise exploratÃ³ria automatizada, engenharia de features, comparaÃ§Ã£o de modelos e otimizaÃ§Ã£o de hiperparÃ¢metros.

## ğŸ¯ Overview / VisÃ£o Geral

A complete Machine Learning system that implements industry best practices for predictive model development, offering end-to-end automation with exploratory analysis, feature engineering, training of multiple algorithms, and robust performance evaluation.

Sistema completo de Machine Learning que implementa as melhores prÃ¡ticas da indÃºstria para desenvolvimento de modelos preditivos, oferecendo automaÃ§Ã£o end-to-end com anÃ¡lise exploratÃ³ria, feature engineering, treinamento de mÃºltiplos algoritmos e avaliaÃ§Ã£o robusta de performance.

### âœ¨ Key Features / CaracterÃ­sticas Principais

- **ğŸ” Automated EDA**: Comprehensive exploratory analysis with professional visualizations
- **âš™ï¸ Feature Engineering**: Automatic feature selection and transformation
- **ğŸ¤– Model Comparison**: Multiple algorithms (Random Forest, Gradient Boosting, Logistic Regression, SVM)
- **ğŸ“Š Cross-Validation**: Robust evaluation with k-fold cross-validation
- **ğŸ›ï¸ Hyperparameter Optimization**: Automatic search with GridSearchCV
- **ğŸ“ˆ Professional Visualizations**: Performance graphs and data insights
- **ğŸ’¾ Model Persistence**: Saving and loading of trained models

- **ğŸ” EDA Automatizada**: AnÃ¡lise exploratÃ³ria abrangente com visualizaÃ§Ãµes profissionais
- **âš™ï¸ Feature Engineering**: SeleÃ§Ã£o e transformaÃ§Ã£o automÃ¡tica de features
- **ğŸ¤– ComparaÃ§Ã£o de Modelos**: MÃºltiplos algoritmos (Random Forest, Gradient Boosting, Logistic Regression, SVM)
- **ğŸ“Š ValidaÃ§Ã£o Cruzada**: AvaliaÃ§Ã£o robusta com k-fold cross-validation
- **ğŸ›ï¸ OtimizaÃ§Ã£o de HiperparÃ¢metros**: Busca automÃ¡tica com GridSearchCV
- **ğŸ“ˆ VisualizaÃ§Ãµes Profissionais**: GrÃ¡ficos de performance e insights dos dados
- **ğŸ’¾ PersistÃªncia de Modelos**: Salvamento e carregamento de modelos treinados

## ğŸ› ï¸ Technology Stack / Stack TecnolÃ³gico

### Core Libraries / Bibliotecas Principais
- **Python 3.11**: Main language / Linguagem principal
- **Scikit-learn**: Machine Learning Framework / Framework de Machine Learning
- **Pandas**: Data manipulation and analysis / ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy**: Numerical computation / ComputaÃ§Ã£o numÃ©rica

### Visualization & Analysis / VisualizaÃ§Ã£o e AnÃ¡lise
- **Matplotlib**: Static visualizations / VisualizaÃ§Ãµes estÃ¡ticas
- **Seaborn**: Statistical visualizations / VisualizaÃ§Ãµes estatÃ­sticas
- **Plotly**: Interactive charts (optional) / GrÃ¡ficos interativos (opcional)

### Model Development / Desenvolvimento de Modelos
- **Random Forest**: Ensemble of decision trees / Ensemble de Ã¡rvores de decisÃ£o
- **Gradient Boosting**: Sequential boosting / Boosting sequencial
- **Logistic Regression**: Logistic regression / RegressÃ£o logÃ­stica
- **Support Vector Machine**: Support vector machines / MÃ¡quinas de vetores de suporte

## ğŸ“ Project Structure / Estrutura do Projeto

```
Advanced-ML-Pipeline/
â”œâ”€â”€ ml_pipeline.py              # Main pipeline / Pipeline principal
â”œâ”€â”€ requirements.txt            # Project dependencies / DependÃªncias do projeto
â”œâ”€â”€ README.md                   # Documentation / DocumentaÃ§Ã£o
â”œâ”€â”€ .gitignore                  # Git ignored files / Arquivos ignorados pelo Git
â”œâ”€â”€ data/                       # Input data (optional) / Dados de entrada (opcional)
â”œâ”€â”€ outputs/                    # Generated results / Resultados gerados
â”‚   â”œâ”€â”€ eda_analysis.png        # EDA visualizations / VisualizaÃ§Ãµes EDA
â”‚   â”œâ”€â”€ model_evaluation.png    # Model comparison / ComparaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ feature_importance.png  # Feature importance / ImportÃ¢ncia das features
â”‚   â””â”€â”€ best_model.pkl          # Best saved model / Melhor modelo salvo
â”œâ”€â”€ notebooks/                  # Jupyter notebooks (optional) / Jupyter notebooks (opcional)
â””â”€â”€ tests/                      # Unit tests / Testes unitÃ¡rios
```

## ğŸš€ Quick Start / InÃ­cio RÃ¡pido

### Prerequisites / PrÃ©-requisitos

- Python 3.11 or higher / Python 3.11 ou superior
- pip (Python package manager) / pip (gerenciador de pacotes Python)

### Installation / InstalaÃ§Ã£o

1. **Clone the repository:** / **Clone o repositÃ³rio:**
```bash
git clone https://github.com/galafis/Advanced-ML-Pipeline.git
cd Advanced-ML-Pipeline
```

2. **Install dependencies:** / **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

3. **Execute the pipeline:** / **Execute o pipeline:**
```bash
python ml_pipeline.py
```

### Basic Usage / Uso BÃ¡sico

```python
from ml_pipeline import MLPipeline
import pandas as pd

# Load your data / Carregue seus dados
data = pd.read_csv(\'your_dataset.csv\')

# Initialize the pipeline / Inicialize o pipeline
pipeline = MLPipeline()

# Execute the complete pipeline / Execute o pipeline completo
results = pipeline.run_pipeline(data, target_column=\'target\')

# Visualize the results / Visualize os resultados
pipeline.plot_results()
```

## ğŸ” Detailed Functionalities / Funcionalidades Detalhadas

### ğŸ“Š Automated Exploratory Data Analysis / AnÃ¡lise ExploratÃ³ria Automatizada

```python
def exploratory_data_analysis(self, data):
    """
    Performs comprehensive exploratory data analysis
    Realiza anÃ¡lise exploratÃ³ria abrangente dos dados
    """
    # Descriptive statistics / EstatÃ­sticas descritivas
    summary_stats = data.describe()
    
    # Missing values analysis / AnÃ¡lise de valores ausentes
    missing_analysis = data.isnull().sum()
    
    # Variable distributions / DistribuiÃ§Ãµes das variÃ¡veis
    self.plot_distributions(data)
    
    # Correlation matrix / Matriz de correlaÃ§Ã£o
    self.plot_correlation_matrix(data)
    
    # Outlier analysis / AnÃ¡lise de outliers
    outliers = self.detect_outliers(data)
    
    return {
        \'summary_stats\': summary_stats,
        \'missing_values\': missing_analysis,
        \'outliers\': outliers
    }
```

### âš™ï¸ Advanced Feature Engineering / Engenharia de Features AvanÃ§ada

```python
def feature_engineering(self, X, y):
    """
    Automated feature engineering
    Engenharia de features automatizada
    """
    # Statistical-based feature selection / SeleÃ§Ã£o de features baseada em estatÃ­sticas
    selector = SelectKBest(score_func=f_classif, k=\'all\')
    X_selected = selector.fit_transform(X, y)
    
    # Normalization/Standardization / NormalizaÃ§Ã£o/PadronizaÃ§Ã£o
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_selected)
    
    # Polynomial feature creation (if applicable) / CriaÃ§Ã£o de features polinomiais (se aplicÃ¡vel)
    if X.shape[1] <= 10:  # Avoid dimensional explosion / Evitar explosÃ£o dimensional
        poly_features = self.create_polynomial_features(X_scaled)
        X_scaled = np.hstack([X_scaled, poly_features])
    
    return X_scaled, selector, scaler
```

### ğŸ¤– Model Comparison / ComparaÃ§Ã£o de Modelos

```python
def compare_models(self, X, y):
    """
    Compares multiple ML algorithms
    Compara mÃºltiplos algoritmos de ML
    """
    results = {}
    
    for name, model in self.models.items():
        # Cross-validation / ValidaÃ§Ã£o cruzada
        cv_scores = cross_val_score(model, X, y, cv=5, scoring=\'accuracy\')
        
        # Training and evaluation / Treinamento e avaliaÃ§Ã£o
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        results[name] = {
            \'cv_mean\': cv_scores.mean(),
            \'cv_std\': cv_scores.std(),
            \'test_accuracy\': accuracy_score(y_test, y_pred),
            \'classification_report\': classification_report(y_test, y_pred),
            \'confusion_matrix\': confusion_matrix(y_test, y_pred)
        }
    
    return results
```

### ğŸ›ï¸ Hyperparameter Optimization / OtimizaÃ§Ã£o de HiperparÃ¢metros

```python
def hyperparameter_tuning(self, model, param_grid, X, y):
    """
    Automatic hyperparameter optimization
    OtimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros
    """
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        cv=5,
        scoring=\'accuracy\',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X, y)
    
    return {
        \'best_params\': grid_search.best_params_,
        \'best_score\': grid_search.best_score_,
        \'best_estimator\': grid_search.best_estimator_
    }
```

## ğŸ“Š Usage Examples / Exemplos de Uso

### 1. Complete Pipeline with Iris Dataset / Pipeline Completo com Dataset Iris

```python
from sklearn.datasets import load_iris
from ml_pipeline import MLPipeline

# Load the dataset / Carregue o dataset
iris = load_iris()
data = pd.DataFrame(iris.data, columns=iris.feature_names)
data["target"] = iris.target

# Execute the pipeline / Execute o pipeline
pipeline = MLPipeline()
results = pipeline.run_complete_pipeline(data, "target")

# Results / Resultados
print(f"Best model: {results["best_model_name"]}")
print(f"Accuracy: {results["best_accuracy"]:.4f}")
```

### 2. Feature Importance Analysis / AnÃ¡lise de ImportÃ¢ncia de Features

```python
# Get feature importance / Obter importÃ¢ncia das features
feature_importance = pipeline.get_feature_importance()

# Plot importance / Plotar importÃ¢ncia
pipeline.plot_feature_importance(feature_importance)
```

### 3. Predictions on New Data / PrediÃ§Ãµes em Novos Dados

```python
# Load saved model / Carregar modelo salvo
best_model = pipeline.load_model("outputs/best_model.pkl")

# Make predictions / Fazer prediÃ§Ãµes
new_data = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]], 
                       columns=["sepal_length", "sepal_width", 
                               "petal_length", "petal_width"])
prediction = best_model.predict(new_data)
probability = best_model.predict_proba(new_data)

print(f"Prediction: {prediction[0]}")
print(f"Probabilities: {probability[0]}")
```

## ğŸ“ˆ Generated Visualizations / VisualizaÃ§Ãµes Geradas

### 1. Exploratory Analysis / AnÃ¡lise ExploratÃ³ria
- Variable distributions / DistribuiÃ§Ãµes das variÃ¡veis
- Correlation matrix / Matriz de correlaÃ§Ã£o
- Box plots for outlier detection / Box plots para detecÃ§Ã£o de outliers
- Scatter plots for relationships between variables / GrÃ¡ficos de dispersÃ£o para relaÃ§Ãµes entre variÃ¡veis

### 2. Model Evaluation / AvaliaÃ§Ã£o de Modelos
- Accuracy comparison / ComparaÃ§Ã£o de acurÃ¡cias
- ROC curves (for binary classification) / Curvas ROC (para classificaÃ§Ã£o binÃ¡ria)
- Confusion matrices / Matrizes de confusÃ£o
- Cross-validation plots / GrÃ¡ficos de validaÃ§Ã£o cruzada

### 3. Feature Analysis / AnÃ¡lise de Features
- Feature importance / ImportÃ¢ncia das features
- Feature selection / SeleÃ§Ã£o de features
- Correlation analysis with target / AnÃ¡lise de correlaÃ§Ã£o com target

## âš¡ Performance and Optimization / Performance e OtimizaÃ§Ã£o

### Performance Metrics / MÃ©tricas de Performance

```python
def performance_metrics(self):
    """
    Calculates comprehensive performance metrics
    Calcula mÃ©tricas abrangentes de performance
    """
    return {
        \'accuracy\': self.accuracy_score,
        \'precision\': self.precision_score,
        \'recall\': self.recall_score,
        \'f1_score\': self.f1_score,
        \'roc_auc\': self.roc_auc_score,
        \'training_time\': self.training_time,
        \'prediction_time\': self.prediction_time
    }
```

### Implemented Optimizations / OtimizaÃ§Ãµes Implementadas

- **Parallelization**: Use of `n_jobs=-1` in supported operations / Uso de `n_jobs=-1` em operaÃ§Ãµes que suportam
- **Efficient Validation**: Optimized cross-validation / Cross-validation otimizada
- **Memory Management**: Automatic temporary variable cleanup / Limpeza automÃ¡tica de variÃ¡veis temporÃ¡rias
- **Caching**: Caching of intermediate results / Cache de resultados intermediÃ¡rios

## ğŸ§ª Tests and Validation / Testes e ValidaÃ§Ã£o

### Run Tests / Executar Testes

```bash
# Unit tests / Testes unitÃ¡rios
python -m pytest tests/

# Integration test / Teste de integraÃ§Ã£o
python tests/test_integration.py

# Performance test / Teste de performance
python tests/test_performance.py
```

### Data Validation / ValidaÃ§Ã£o de Dados

```python
def validate_data(self, data):
    """
    Comprehensive validation of input data
    ValidaÃ§Ã£o abrangente dos dados de entrada
    """
    validations = {
        'shape_check': data.shape[0] > 0 and data.shape[1] > 0,
        'missing_values': data.isnull().sum().sum(),
        'data_types': data.dtypes.to_dict(),
        'duplicates': data.duplicated().sum(),
        'memory_usage': data.memory_usage(deep=True).sum()
    }
    
    return validations
```

## ğŸ“Š Use Cases / Casos de Uso

### 1. Customer Classification / ClassificaÃ§Ã£o de Clientes
- Customer segmentation by behavior / SegmentaÃ§Ã£o de clientes por comportamento
- Churn prediction / PrediÃ§Ã£o de churn
- Lifetime value analysis / AnÃ¡lise de lifetime value

### 2. Medical Analysis / AnÃ¡lise MÃ©dica
- ML-assisted diagnosis / DiagnÃ³stico assistido por ML
- Laboratory exam analysis / AnÃ¡lise de exames laboratoriais
- Risk prediction / PrediÃ§Ã£o de riscos

### 3. Financial Analysis / AnÃ¡lise Financeira
- Fraud detection / DetecÃ§Ã£o de fraudes
- Credit analysis / AnÃ¡lise de crÃ©dito
- Market prediction / PrediÃ§Ã£o de mercado

## ğŸ”§ Advanced Configuration / ConfiguraÃ§Ã£o AvanÃ§ada

### Configuration File / Arquivo de ConfiguraÃ§Ã£o

```python
# config.py
ML_CONFIG = {
    'random_state': 42,
    'test_size': 0.2,
    'cv_folds': 5,
    'n_jobs': -1,
    'verbose': True,
    'save_models': True,
    'output_dir': 'outputs/'
}

VISUALIZATION_CONFIG = {
    'figure_size': (12, 8),
    'dpi': 300,
    'style': 'seaborn-v0_8',
    'color_palette': 'viridis'
}
```

### Model Parameters / ParÃ¢metros de Modelos

```python
HYPERPARAMETER_GRIDS = {
    'Random Forest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'Gradient Boosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
}
```

## ğŸ“„ License / LicenÃ§a

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Demetrios Lafis**

- GitHub: [@galafis](https://github.com/galafis)
- Email: gabrieldemetrios@gmail.com

---

â­ Se este projeto foi Ãºtil, considere deixar uma estrela!



## ğŸ™ Acknowledgments / Agradecimentos

Special thanks to all contributors and the open-source community for their invaluable support and resources.
Um agradecimento especial a todos os contribuidores e Ã  comunidade open-source pelo seu inestimÃ¡vel apoio e recursos.

