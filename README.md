# Advanced Machine Learning Pipeline

![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat&logo=matplotlib&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=flat&logo=python&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

Um pipeline avan√ßado de Machine Learning que automatiza todo o fluxo de trabalho de ML, desde o pr√©-processamento de dados at√© a avalia√ß√£o de modelos. Este projeto demonstra t√©cnicas avan√ßadas de ci√™ncia de dados, incluindo an√°lise explorat√≥ria automatizada, engenharia de features, compara√ß√£o de modelos e otimiza√ß√£o de hiperpar√¢metros.

An advanced Machine Learning Pipeline that automates the entire ML workflow, from data preprocessing to model evaluation. This project demonstrates advanced data science techniques including automated exploratory analysis, feature engineering, model comparison, and hyperparameter optimization.

## üéØ Overview / Vis√£o Geral

Um sistema completo de Machine Learning que implementa as melhores pr√°ticas da ind√∫stria para o desenvolvimento de modelos preditivos, oferecendo automa√ß√£o de ponta a ponta com an√°lise explorat√≥ria, engenharia de features, treinamento de m√∫ltiplos algoritmos e avalia√ß√£o robusta de performance.

A complete Machine Learning system that implements industry best practices for predictive model development, offering end-to-end automation with exploratory analysis, feature engineering, training of multiple algorithms, and robust performance evaluation.

### ‚ú® Key Features / Caracter√≠sticas Principais

- **üîç Automated EDA / EDA Automatizada**: An√°lise explorat√≥ria abrangente com visualiza√ß√µes profissionais.
- **‚öôÔ∏è Feature Engineering / Engenharia de Features**: Sele√ß√£o e transforma√ß√£o autom√°tica de features.
- **ü§ñ Model Comparison / Compara√ß√£o de Modelos**: M√∫ltiplos algoritmos (Random Forest, Gradient Boosting, Logistic Regression, SVM).
- **üìä Cross-Validation / Valida√ß√£o Cruzada**: Avalia√ß√£o robusta com k-fold cross-validation.
- **üéõÔ∏è Hyperparameter Optimization / Otimiza√ß√£o de Hiperpar√¢metros**: Busca autom√°tica com GridSearchCV.
- **üìà Professional Visualizations / Visualiza√ß√µes Profissionais**: Gr√°ficos de performance e insights dos dados.
- **üíæ Model Persistence / Persist√™ncia de Modelos**: Salvamento e carregamento de modelos treinados.

## üõ†Ô∏è Technology Stack / Stack Tecnol√≥gico

### Core Libraries / Bibliotecas Principais
- **Python 3.11+**: Main language / Linguagem principal
- **Scikit-learn**: Machine Learning Framework / Framework de Machine Learning
- **Pandas**: Data manipulation and analysis / Manipula√ß√£o e an√°lise de dados
- **NumPy**: Numerical computation / Computa√ß√£o num√©rica

### Visualization & Analysis / Visualiza√ß√£o e An√°lise
- **Matplotlib**: Static visualizations / Visualiza√ß√µes est√°ticas
- **Seaborn**: Statistical visualizations / Visualiza√ß√µes estat√≠sticas

### Model Development / Desenvolvimento de Modelos
- **Random Forest**: Ensemble of decision trees / Ensemble de √°rvores de decis√£o
- **Gradient Boosting**: Sequential boosting / Boosting sequencial
- **Logistic Regression**: Logistic regression / Regress√£o log√≠stica
- **Support Vector Machine**: Support vector machines / M√°quinas de vetores de suporte

## üìÅ Project Structure / Estrutura do Projeto

```
Advanced-ML-Pipeline/
‚îú‚îÄ‚îÄ ml_pipeline.py              # Main pipeline / Pipeline principal
‚îú‚îÄ‚îÄ requirements.txt            # Project dependencies / Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                   # Documentation / Documenta√ß√£o
‚îú‚îÄ‚îÄ .gitignore                  # Git ignored files / Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ config.py                   # Configuration settings / Configura√ß√µes do projeto
‚îú‚îÄ‚îÄ data/                       # Input data (optional) / Dados de entrada (opcional)
‚îú‚îÄ‚îÄ outputs/                    # Generated results / Resultados gerados
‚îÇ   ‚îú‚îÄ‚îÄ eda_analysis.png        # EDA visualizations / Visualiza√ß√µes EDA
‚îÇ   ‚îú‚îÄ‚îÄ model_evaluation.png    # Model comparison / Compara√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.png  # Feature importance / Import√¢ncia das features
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pkl          # Best saved model / Melhor modelo salvo
‚îú‚îÄ‚îÄ notebooks/                  # Jupyter notebooks (optional) / Jupyter notebooks (opcional)
‚îî‚îÄ‚îÄ tests/                      # Unit and integration tests / Testes unit√°rios e de integra√ß√£o
```

## üöÄ Quick Start / In√≠cio R√°pido

### Prerequisites / Pr√©-requisitos

- Python 3.11 or higher / Python 3.11 ou superior
- pip (Python package manager) / pip (gerenciador de pacotes Python)

### Installation / Instala√ß√£o

1. **Clone the repository:** / **Clone o reposit√≥rio:**
```bash
git clone https://github.com/galafis/Advanced-ML-Pipeline.git
cd Advanced-ML-Pipeline
```

2. **Install dependencies:** / **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

3. **Execute the pipeline:** / **Execute o pipeline:**
```bash
python ml_pipeline.py
```

### Basic Usage / Uso B√°sico

```python
from ml_pipeline import MLPipeline
import pandas as pd

# Load your data / Carregue seus dados
# Exemplo com dados de demonstra√ß√£o (Iris dataset)
from sklearn.datasets import load_iris
iris = load_iris()
data = pd.DataFrame(iris.data, columns=iris.feature_names)
data["target"] = iris.target

# Initialize the pipeline / Inicialize o pipeline
pipeline = MLPipeline()

# Execute the complete pipeline / Execute o pipeline completo
# Certifique-se de que a coluna 'target' existe em seus dados
results = pipeline.run_pipeline(data_frame=data, target_column='target')
```

## üîç Detailed Functionalities / Funcionalidades Detalhadas

### üìä Automated Exploratory Data Analysis / An√°lise Explorat√≥ria Automatizada

O pipeline inclui uma fase de An√°lise Explorat√≥ria de Dados (EDA) automatizada, que gera estat√≠sticas descritivas, analisa valores ausentes, visualiza distribui√ß√µes de vari√°veis, matrizes de correla√ß√£o e detecta outliers. Isso fornece uma compreens√£o profunda dos dados antes do treinamento do modelo.

The pipeline includes an automated Exploratory Data Analysis (EDA) phase, which generates descriptive statistics, analyzes missing values, visualizes variable distributions, correlation matrices, and detects outliers. This provides a deep understanding of the data before model training.

### ‚öôÔ∏è Advanced Feature Engineering / Engenharia de Features Avan√ßada

Esta se√ß√£o do pipeline lida com a sele√ß√£o e transforma√ß√£o autom√°tica de features. Inclui sele√ß√£o de features baseada em estat√≠sticas (e.g., `SelectKBest`), normaliza√ß√£o/padroniza√ß√£o de dados (`StandardScaler`) e, se aplic√°vel, cria√ß√£o de features polinomiais para capturar rela√ß√µes n√£o lineares.

This section of the pipeline handles automatic feature selection and transformation. It includes statistical-based feature selection (e.g., `SelectKBest`), data normalization/standardization (`StandardScaler`), and, if applicable, polynomial feature creation to capture non-linear relationships.

### ü§ñ Model Comparison / Compara√ß√£o de Modelos

O pipeline compara m√∫ltiplos algoritmos de Machine Learning, como Random Forest, Gradient Boosting, Regress√£o Log√≠stica e SVM. Cada modelo √© avaliado usando valida√ß√£o cruzada (k-fold) e m√©tricas de desempenho robustas para identificar o melhor modelo para o conjunto de dados.

The pipeline compares multiple Machine Learning algorithms, such as Random Forest, Gradient Boosting, Logistic Regression, and SVM. Each model is evaluated using k-fold cross-validation and robust performance metrics to identify the best model for the dataset.

### üéõÔ∏è Hyperparameter Optimization / Otimiza√ß√£o de Hiperpar√¢metros

Para garantir o desempenho ideal do modelo, o pipeline incorpora otimiza√ß√£o autom√°tica de hiperpar√¢metros usando `GridSearchCV`. Isso busca sistematicamente a melhor combina√ß√£o de hiperpar√¢metros para o modelo selecionado, melhorando sua acur√°cia e generaliza√ß√£o.

To ensure optimal model performance, the pipeline incorporates automatic hyperparameter optimization using `GridSearchCV`. This systematically searches for the best combination of hyperparameters for the selected model, improving its accuracy and generalization.

## üìä Usage Examples / Exemplos de Uso

### 1. Complete Pipeline with Iris Dataset / Pipeline Completo com Dataset Iris

Este exemplo demonstra como executar o pipeline completo usando o popular dataset Iris. Ele carrega os dados, inicializa o pipeline, executa todas as etapas (EDA, pr√©-processamento, treinamento, otimiza√ß√£o) e gera um relat√≥rio de avalia√ß√£o.

This example demonstrates how to run the complete pipeline using the popular Iris dataset. It loads the data, initializes the pipeline, executes all steps (EDA, preprocessing, training, optimization), and generates an evaluation report.

```python
from sklearn.datasets import load_iris
from ml_pipeline import MLPipeline
import pandas as pd

# Load the dataset / Carregue o dataset
iris = load_iris()
data = pd.DataFrame(iris.data, columns=iris.feature_names)
data["target"] = iris.target

# Execute the pipeline / Execute o pipeline
pipeline = MLPipeline()
results = pipeline.run_pipeline(data_frame=data, target_column="target")

# Results / Resultados
print(f"Best model: {pipeline.best_model_name}")
print(f"Accuracy: {pipeline.best_score:.4f}")
```

### 2. Feature Importance Analysis / An√°lise de Import√¢ncia de Features

Ap√≥s o treinamento do modelo, √© poss√≠vel analisar a import√¢ncia das features para entender quais vari√°veis contribuem mais para as previs√µes do modelo. O pipeline pode gerar visualiza√ß√µes para essa an√°lise.

After model training, it's possible to analyze feature importance to understand which variables contribute most to the model's predictions. The pipeline can generate visualizations for this analysis.

```python
# Assuming pipeline.run_pipeline has been executed
# Supondo que pipeline.run_pipeline tenha sido executado

# Get feature importance / Obter import√¢ncia das features
feature_importance = pipeline.get_feature_importance()

# Plot importance / Plotar import√¢ncia
pipeline.plot_feature_importance(feature_importance)
```

### 3. Predictions on New Data / Predi√ß√µes em Novos Dados

O modelo treinado e otimizado pode ser salvo e posteriormente carregado para fazer previs√µes em novos dados. Isso demonstra a capacidade de implanta√ß√£o do pipeline.

The trained and optimized model can be saved and later loaded to make predictions on new data. This demonstrates the deployment capability of the pipeline.

```python
import pandas as pd
from ml_pipeline import MLPipeline

# Initialize pipeline to load model / Inicializar pipeline para carregar modelo
pipeline = MLPipeline()

# Load saved model / Carregar modelo salvo
best_model_data = pipeline.load_model("best_model.pkl")
best_model = best_model_data["model"]
scaler = best_model_data["scaler"]
feature_selector = best_model_data["feature_selector"]

# Make predictions / Fazer predi√ß√µes
new_data = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]], 
                       columns=["sepal length (cm)", "sepal width (cm)", 
                               "petal length (cm)", "petal width (cm)"])

# Apply the same preprocessing transformations (scale, then select)
new_data_scaled = scaler.transform(new_data)
new_data_selected = feature_selector.transform(new_data_scaled)

prediction = best_model.predict(new_data_selected)
probability = best_model.predict_proba(new_data_selected)

print(f"Prediction: {prediction[0]}")
print(f"Probabilities: {probability[0]}")
```

## üìà Generated Visualizations / Visualiza√ß√µes Geradas

O pipeline gera automaticamente v√°rias visualiza√ß√µes para auxiliar na compreens√£o dos dados e na avalia√ß√£o do modelo. Essas visualiza√ß√µes s√£o salvas no diret√≥rio `outputs/`.

The pipeline automatically generates various visualizations to aid in data understanding and model evaluation. These visualizations are saved in the `outputs/` directory.

### 1. Exploratory Analysis / An√°lise Explorat√≥ria
- **Variable distributions / Distribui√ß√µes das vari√°veis**: Histogramas e gr√°ficos de densidade para entender a forma dos dados.
- **Correlation matrix / Matriz de correla√ß√£o**: Mapa de calor mostrando a correla√ß√£o entre as features.
- **Box plots for outlier detection / Box plots para detec√ß√£o de outliers**: Identifica√ß√£o visual de valores at√≠picos.

### 2. Model Evaluation / Avalia√ß√£o de Modelos
- **Accuracy comparison / Compara√ß√£o de acur√°cias**: Gr√°ficos de barras comparando o desempenho de diferentes modelos.
- **Confusion matrices / Matrizes de confus√£o**: Detalhamento dos verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos.

### 3. Feature Analysis / An√°lise de Features
- **Feature importance / Import√¢ncia das features**: Gr√°ficos mostrando a contribui√ß√£o de cada feature para o modelo.

## ‚ö° Performance and Optimization / Performance e Otimiza√ß√£o

O pipeline √© projetado com foco em performance e otimiza√ß√£o, utilizando t√©cnicas como paraleliza√ß√£o e gerenciamento eficiente de mem√≥ria.

The pipeline is designed with a focus on performance and optimization, utilizing techniques such as parallelization and efficient memory management.

### Performance Metrics / M√©tricas de Performance

O pipeline calcula e reporta m√©tricas de desempenho para cada modelo, incluindo acur√°cia, precis√£o, recall e F1-score.

The pipeline calculates and reports performance metrics for each model, including accuracy, precision, recall, and F1-score.

### Implemented Optimizations / Otimiza√ß√µes Implementadas

- **Parallelization / Paraleliza√ß√£o**: Uso de `n_jobs=-1` em opera√ß√µes suportadas para aproveitar m√∫ltiplos n√∫cleos de CPU.
- **Efficient Validation / Valida√ß√£o Eficiente**: Valida√ß√£o cruzada otimizada para reduzir o tempo de computa√ß√£o.

## üß™ Tests and Validation / Testes e Valida√ß√£o

O projeto inclui um conjunto de testes para garantir a funcionalidade e a robustez do pipeline.

The project includes a suite of tests to ensure the functionality and robustness of the pipeline.

### Run Tests / Executar Testes

Para executar os testes, navegue at√© o diret√≥rio raiz do projeto e use os seguintes comandos:

To run the tests, navigate to the project root directory and use the following commands:

```bash
# Unit tests / Testes unit√°rios
python -m pytest tests/test_pipeline.py

# Integration test / Teste de integra√ß√£o
python -m pytest tests/test_integration.py

# Performance test / Teste de performance
python -m pytest tests/test_performance.py
```

### Data Validation / Valida√ß√£o de Dados

O pipeline valida os dados de entrada verificando se a coluna alvo existe e se o DataFrame cont√©m dados v√°lidos antes de iniciar o processamento.

The pipeline validates input data by checking that the target column exists and that the DataFrame contains valid data before starting processing.

##  Advanced Configuration / Configura√ß√£o Avan√ßada

### Configuration File / Arquivo de Configura√ß√£o

O arquivo `config.py` centraliza todas as configura√ß√µes do pipeline, permitindo f√°cil personaliza√ß√£o de par√¢metros como `random_state`, `test_size`, `cv_folds`, diret√≥rios de sa√≠da e op√ß√µes de verbosidade.

The `config.py` file centralizes all pipeline configurations, allowing easy customization of parameters such as `random_state`, `test_size`, `cv_folds`, output directories, and verbosity options.

```python
# config.py
ML_CONFIG = {
    'random_state': 42,
    'test_size': 0.2,
    'cv_folds': 5,
    'n_jobs': -1,
    'verbose': True,
    'save_models': True,
    'output_dir': 'outputs/'
}

VISUALIZATION_CONFIG = {
    'figure_size': (12, 8),
    'dpi': 300,
    'style': 'whitegrid',
    'color_palette': 'viridis'
}
```

### Model Parameters / Par√¢metros de Modelos

As grades de hiperpar√¢metros para otimiza√ß√£o s√£o definidas em `config.py`, permitindo que os usu√°rios especifiquem os intervalos de busca para diferentes modelos de ML, como Random Forest e Gradient Boosting.

Hyperparameter grids for optimization are defined in `config.py`, allowing users to specify search ranges for different ML models, such as Random Forest and Gradient Boosting.

```python
HYPERPARAMETER_GRIDS = {
    'Random Forest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'Gradient Boosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    },
    'Logistic Regression': {
        'C': [0.01, 0.1, 1, 10],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga']
    },
    'SVM': {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf'],
        'gamma': ['scale', 'auto']
    }
}
```

## üìÑ License / Licen√ßa

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üë®‚Äçüíª Autor

**Gabriel Demetrios Lafis**

- GitHub: [@galafis](https://github.com/galafis)
- Email: gabrieldemetrios@gmail.com

