# Advanced Machine Learning Pipeline

![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat&logo=matplotlib&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=flat&logo=python&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

Pipeline avanÃ§ado de Machine Learning que automatiza todo o fluxo de trabalho ML, desde o prÃ©-processamento de dados atÃ© a avaliaÃ§Ã£o de modelos. Este projeto demonstra tÃ©cnicas avanÃ§adas de ciÃªncia de dados incluindo anÃ¡lise exploratÃ³ria automatizada, engenharia de features, comparaÃ§Ã£o de modelos e otimizaÃ§Ã£o de hiperparÃ¢metros.

## ğŸ¯ VisÃ£o Geral

Sistema completo de Machine Learning que implementa as melhores prÃ¡ticas da indÃºstria para desenvolvimento de modelos preditivos, oferecendo automaÃ§Ã£o end-to-end com anÃ¡lise exploratÃ³ria, feature engineering, treinamento de mÃºltiplos algoritmos e avaliaÃ§Ã£o robusta de performance.

### âœ¨ CaracterÃ­sticas Principais

- **ğŸ” EDA Automatizada**: AnÃ¡lise exploratÃ³ria abrangente com visualizaÃ§Ãµes profissionais
- **âš™ï¸ Feature Engineering**: SeleÃ§Ã£o e transformaÃ§Ã£o automÃ¡tica de features
- **ğŸ¤– ComparaÃ§Ã£o de Modelos**: MÃºltiplos algoritmos (Random Forest, Gradient Boosting, Logistic Regression, SVM)
- **ğŸ“Š ValidaÃ§Ã£o Cruzada**: AvaliaÃ§Ã£o robusta com k-fold cross-validation
- **ğŸ›ï¸ OtimizaÃ§Ã£o de HiperparÃ¢metros**: Busca automÃ¡tica com GridSearchCV
- **ğŸ“ˆ VisualizaÃ§Ãµes Profissionais**: GrÃ¡ficos de performance e insights dos dados
- **ğŸ’¾ PersistÃªncia de Modelos**: Salvamento e carregamento de modelos treinados

## ğŸ› ï¸ Stack TecnolÃ³gico

### Core Libraries
- **Python 3.11**: Linguagem principal
- **Scikit-learn**: Framework de Machine Learning
- **Pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica

### Visualization & Analysis
- **Matplotlib**: VisualizaÃ§Ãµes estÃ¡ticas
- **Seaborn**: VisualizaÃ§Ãµes estatÃ­sticas
- **Plotly**: GrÃ¡ficos interativos (opcional)

### Model Development
- **Random Forest**: Ensemble de Ã¡rvores de decisÃ£o
- **Gradient Boosting**: Boosting sequencial
- **Logistic Regression**: RegressÃ£o logÃ­stica
- **Support Vector Machine**: MÃ¡quinas de vetores de suporte

## ğŸ“ Estrutura do Projeto

```
Advanced-ML-Pipeline/
â”œâ”€â”€ ml_pipeline.py              # Pipeline principal
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o
â”œâ”€â”€ .gitignore                  # Arquivos ignorados pelo Git
â”œâ”€â”€ data/                       # Dados de entrada (opcional)
â”œâ”€â”€ outputs/                    # Resultados gerados
â”‚   â”œâ”€â”€ eda_analysis.png        # VisualizaÃ§Ãµes EDA
â”‚   â”œâ”€â”€ model_evaluation.png    # ComparaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ feature_importance.png  # ImportÃ¢ncia das features
â”‚   â””â”€â”€ best_model.pkl          # Melhor modelo salvo
â”œâ”€â”€ notebooks/                  # Jupyter notebooks (opcional)
â””â”€â”€ tests/                      # Testes unitÃ¡rios
```

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Python 3.11 ou superior
- pip (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/galafis/Advanced-ML-Pipeline.git
cd Advanced-ML-Pipeline
```

2. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

3. **Execute o pipeline:**
```bash
python ml_pipeline.py
```

### Uso BÃ¡sico

```python
from ml_pipeline import MLPipeline
import pandas as pd

# Carregue seus dados
data = pd.read_csv('your_dataset.csv')

# Inicialize o pipeline
pipeline = MLPipeline()

# Execute o pipeline completo
results = pipeline.run_pipeline(data, target_column='target')

# Visualize os resultados
pipeline.plot_results()
```

## ğŸ” Funcionalidades Detalhadas

### ğŸ“Š AnÃ¡lise ExploratÃ³ria Automatizada

```python
def exploratory_data_analysis(self, data):
    """
    Realiza anÃ¡lise exploratÃ³ria abrangente dos dados
    """
    # EstatÃ­sticas descritivas
    summary_stats = data.describe()
    
    # AnÃ¡lise de valores ausentes
    missing_analysis = data.isnull().sum()
    
    # DistribuiÃ§Ãµes das variÃ¡veis
    self.plot_distributions(data)
    
    # Matriz de correlaÃ§Ã£o
    self.plot_correlation_matrix(data)
    
    # AnÃ¡lise de outliers
    outliers = self.detect_outliers(data)
    
    return {
        'summary_stats': summary_stats,
        'missing_values': missing_analysis,
        'outliers': outliers
    }
```

### âš™ï¸ Feature Engineering AvanÃ§ado

```python
def feature_engineering(self, X, y):
    """
    Engenharia de features automatizada
    """
    # SeleÃ§Ã£o de features baseada em estatÃ­sticas
    selector = SelectKBest(score_func=f_classif, k='all')
    X_selected = selector.fit_transform(X, y)
    
    # NormalizaÃ§Ã£o/PadronizaÃ§Ã£o
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_selected)
    
    # CriaÃ§Ã£o de features polinomiais (se aplicÃ¡vel)
    if X.shape[1] <= 10:  # Evitar explosÃ£o dimensional
        poly_features = self.create_polynomial_features(X_scaled)
        X_scaled = np.hstack([X_scaled, poly_features])
    
    return X_scaled, selector, scaler
```

### ğŸ¤– ComparaÃ§Ã£o de Modelos

```python
def compare_models(self, X, y):
    """
    Compara mÃºltiplos algoritmos de ML
    """
    results = {}
    
    for name, model in self.models.items():
        # ValidaÃ§Ã£o cruzada
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
        
        # Treinamento e avaliaÃ§Ã£o
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        results[name] = {
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'test_accuracy': accuracy_score(y_test, y_pred),
            'classification_report': classification_report(y_test, y_pred),
            'confusion_matrix': confusion_matrix(y_test, y_pred)
        }
    
    return results
```

### ğŸ›ï¸ OtimizaÃ§Ã£o de HiperparÃ¢metros

```python
def hyperparameter_tuning(self, model, param_grid, X, y):
    """
    OtimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros
    """
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X, y)
    
    return {
        'best_params': grid_search.best_params_,
        'best_score': grid_search.best_score_,
        'best_estimator': grid_search.best_estimator_
    }
```

## ğŸ“Š Exemplos de Uso

### 1. Pipeline Completo com Dataset Iris

```python
from sklearn.datasets import load_iris
from ml_pipeline import MLPipeline

# Carregue o dataset
iris = load_iris()
data = pd.DataFrame(iris.data, columns=iris.feature_names)
data['target'] = iris.target

# Execute o pipeline
pipeline = MLPipeline()
results = pipeline.run_complete_pipeline(data, 'target')

# Resultados
print(f"Melhor modelo: {results['best_model_name']}")
print(f"AcurÃ¡cia: {results['best_accuracy']:.4f}")
```

### 2. AnÃ¡lise de Feature Importance

```python
# Obter importÃ¢ncia das features
feature_importance = pipeline.get_feature_importance()

# Plotar importÃ¢ncia
pipeline.plot_feature_importance(feature_importance)
```

### 3. PrediÃ§Ãµes em Novos Dados

```python
# Carregar modelo salvo
best_model = pipeline.load_model('outputs/best_model.pkl')

# Fazer prediÃ§Ãµes
new_data = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]], 
                       columns=['sepal_length', 'sepal_width', 
                               'petal_length', 'petal_width'])
prediction = best_model.predict(new_data)
probability = best_model.predict_proba(new_data)

print(f"PrediÃ§Ã£o: {prediction[0]}")
print(f"Probabilidades: {probability[0]}")
```

## ğŸ“ˆ VisualizaÃ§Ãµes Geradas

### 1. AnÃ¡lise ExploratÃ³ria
- DistribuiÃ§Ãµes das variÃ¡veis
- Matriz de correlaÃ§Ã£o
- Box plots para detecÃ§Ã£o de outliers
- GrÃ¡ficos de dispersÃ£o para relaÃ§Ãµes entre variÃ¡veis

### 2. AvaliaÃ§Ã£o de Modelos
- ComparaÃ§Ã£o de acurÃ¡cias
- Curvas ROC (para classificaÃ§Ã£o binÃ¡ria)
- Matrizes de confusÃ£o
- GrÃ¡ficos de validaÃ§Ã£o cruzada

### 3. Feature Analysis
- ImportÃ¢ncia das features
- SeleÃ§Ã£o de features
- AnÃ¡lise de correlaÃ§Ã£o com target

## âš¡ Performance e OtimizaÃ§Ã£o

### MÃ©tricas de Performance

```python
def performance_metrics(self):
    """
    Calcula mÃ©tricas abrangentes de performance
    """
    return {
        'accuracy': self.accuracy_score,
        'precision': self.precision_score,
        'recall': self.recall_score,
        'f1_score': self.f1_score,
        'roc_auc': self.roc_auc_score,
        'training_time': self.training_time,
        'prediction_time': self.prediction_time
    }
```

### OtimizaÃ§Ãµes Implementadas

- **ParalelizaÃ§Ã£o**: Uso de `n_jobs=-1` em operaÃ§Ãµes que suportam
- **ValidaÃ§Ã£o Eficiente**: Cross-validation otimizada
- **Memory Management**: Limpeza automÃ¡tica de variÃ¡veis temporÃ¡rias
- **Caching**: Cache de resultados intermediÃ¡rios

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Executar Testes

```bash
# Testes unitÃ¡rios
python -m pytest tests/

# Teste de integraÃ§Ã£o
python tests/test_integration.py

# Teste de performance
python tests/test_performance.py
```

### ValidaÃ§Ã£o de Dados

```python
def validate_data(self, data):
    """
    ValidaÃ§Ã£o abrangente dos dados de entrada
    """
    validations = {
        'shape_check': data.shape[0] > 0 and data.shape[1] > 0,
        'missing_values': data.isnull().sum().sum(),
        'data_types': data.dtypes.to_dict(),
        'duplicates': data.duplicated().sum(),
        'memory_usage': data.memory_usage(deep=True).sum()
    }
    
    return validations
```

## ğŸ“Š Casos de Uso

### 1. ClassificaÃ§Ã£o de Clientes
- SegmentaÃ§Ã£o de clientes por comportamento
- PrediÃ§Ã£o de churn
- AnÃ¡lise de lifetime value

### 2. AnÃ¡lise MÃ©dica
- DiagnÃ³stico assistido por ML
- AnÃ¡lise de exames laboratoriais
- PrediÃ§Ã£o de riscos

### 3. AnÃ¡lise Financeira
- DetecÃ§Ã£o de fraudes
- AnÃ¡lise de crÃ©dito
- PrediÃ§Ã£o de mercado

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Arquivo de ConfiguraÃ§Ã£o

```python
# config.py
ML_CONFIG = {
    'random_state': 42,
    'test_size': 0.2,
    'cv_folds': 5,
    'n_jobs': -1,
    'verbose': True,
    'save_models': True,
    'output_dir': 'outputs/'
}

VISUALIZATION_CONFIG = {
    'figure_size': (12, 8),
    'dpi': 300,
    'style': 'seaborn-v0_8',
    'color_palette': 'viridis'
}
```

### ParÃ¢metros de Modelos

```python
HYPERPARAMETER_GRIDS = {
    'Random Forest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'Gradient Boosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
}
```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Demetrios Lafis**

- GitHub: [@galafis](https://github.com/galafis)
- Email: gabrieldemetrios@gmail.com

---

â­ Se este projeto foi Ãºtil, considere deixar uma estrela!

